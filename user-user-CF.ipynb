{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9498229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ee95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tag_matrix = pd.read_csv(\"subset_movie_tag_matrix.csv\", index_col=0)\n",
    "ratings_small    = pd.read_csv(\"subset_ratings.csv\")\n",
    "movies_small     = pd.read_csv(\"subset_movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d2bf84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tag‑matrix shape: (7008, 1128)\n"
     ]
    }
   ],
   "source": [
    "movie_tag_matrix.index = movie_tag_matrix.index.astype(int)\n",
    "print(\"Loaded tag‑matrix shape:\", movie_tag_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9715b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_norms   = np.linalg.norm(movie_tag_matrix.values, axis=1)\n",
    "movie_norm  = movie_tag_matrix.div(\n",
    "    pd.Series(row_norms, index=movie_tag_matrix.index).replace(0, 1),\n",
    "    axis=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0d9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_per_user(df: pd.DataFrame, test_fraction: float = 0.20, seed: int = 7):\n",
    "    \"\"\"Return (train_df, test_df) with an 80‑20 split for each individual user.\"\"\"\n",
    "    train, test = [], []\n",
    "    for _uid, grp in df.groupby(\"userId\"):\n",
    "        if len(grp) == 1:\n",
    "            train.append(grp)\n",
    "            continue\n",
    "        tr, te = train_test_split(grp, test_size=test_fraction, random_state=seed)\n",
    "        train.append(tr)\n",
    "        test.append(te)\n",
    "    return pd.concat(train), pd.concat(test)\n",
    "\n",
    "train_ratings, test_ratings = split_per_user(ratings_small, 0.2)\n",
    "valid_movie_ids = set(movie_norm.index)\n",
    "train_ratings   = train_ratings[train_ratings.movieId.isin(valid_movie_ids)].reset_index(drop=True)\n",
    "test_ratings    = test_ratings [test_ratings .movieId.isin(valid_movie_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a81fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating, max_rating = train_ratings.rating.min(), train_ratings.rating.max()\n",
    "\n",
    "user_profiles = {}\n",
    "for u, grp in train_ratings.groupby(\"userId\"):\n",
    "    feats   = movie_norm.loc[grp.movieId].values\n",
    "    weights = ((grp.rating - min_rating) / (max_rating - min_rating)).values[:, None]\n",
    "    vec     = (weights * feats).sum(axis=0)\n",
    "    if vec.sum() > 0:\n",
    "        vec /= np.linalg.norm(vec)\n",
    "    user_profiles[u] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b29721",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot     = train_ratings.pivot(index=\"userId\", columns=\"movieId\", values=\"rating\").fillna(0)\n",
    "user_ids  = pivot.index.values               # length = U\n",
    "movie_ids = pivot.columns.values.astype(int) # length = M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4407dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs  = pivot.values                    # shape (U, M)\n",
    "sim_users  = cosine_similarity(user_vecs)    # (U, U)\n",
    "abs_sim_u  = np.sum(np.abs(sim_users), axis=1)  # denom per user (length U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78e679d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_norm_arr = movie_norm.loc[movie_ids].values  # align order\n",
    "\n",
    "\n",
    "def recommend_hybrid_fast_uCF(user_id: int, K: int = 10, a: float = 0.7):\n",
    "    \"\"\"Return Top‑K movie recommendations using user‑user CF + CBF blend.\"\"\"\n",
    "    if user_id not in pivot.index:\n",
    "        return pd.DataFrame(columns=[\"title\", \"genres\", \"score\"])\n",
    "\n",
    "    u_idx   = np.where(user_ids == user_id)[0][0]\n",
    "\n",
    "    cf_num  = sim_users[u_idx].dot(user_vecs)\n",
    "    cf      = np.divide(cf_num,\n",
    "                        abs_sim_u[u_idx],\n",
    "                        out=np.zeros_like(cf_num),\n",
    "                        where=abs_sim_u[u_idx] > 0)\n",
    "\n",
    "    p_u     = user_profiles.get(user_id, np.zeros(movie_norm_arr.shape[1]))\n",
    "    cbf     = movie_norm_arr.dot(p_u)                # shape (M,)\n",
    "\n",
    "    hyb     = a * cf + (1.0 - a) * cbf\n",
    "\n",
    "    watched = set(train_ratings.loc[train_ratings.userId == user_id, \"movieId\"])\n",
    "    mask    = np.isin(movie_ids, list(watched), invert=True)\n",
    "    hyb    *= mask\n",
    "\n",
    "    if K < len(hyb):\n",
    "        idx      = np.argpartition(-hyb, K)[:K]\n",
    "    else:\n",
    "        idx      = np.arange(len(hyb))\n",
    "    order        = np.argsort(-hyb[idx])\n",
    "    top_ids      = movie_ids[idx][order]\n",
    "    top_scores   = hyb[idx][order]\n",
    "\n",
    "    df = movies_small.set_index(\"movieId\").loc[top_ids, [\"title\", \"genres\"]].copy()\n",
    "    df[\"score\"] = top_scores\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe845583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# — full movie list from your tag‐matrix —\n",
    "all_movies = np.array(sorted(movie_norm.index), dtype=int)\n",
    "movie_norm_full = movie_norm.loc[all_movies].values   # (M_full × T)\n",
    "\n",
    "# — train_movies are exactly the columns in your CF pivot —\n",
    "train_movies = pivot.columns.values.astype(int)       # (M',)\n",
    "# sim_matrix here is already M'×M' from pivot.columns\n",
    "\n",
    "pos_train_in_all = np.searchsorted(all_movies, train_movies)\n",
    "\n",
    "\n",
    "def recommend_hybrid_item(\n",
    "    user_id:int,\n",
    "    K:int=10,\n",
    "    a:float=0.7\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Hybrid recommender for ITEM‐cold scenario.\n",
    "    Blends item–item CF (computed only on train_movies)\n",
    "    with CBF on all_movies.\n",
    "    \"\"\"\n",
    "    if user_id not in pivot.index:\n",
    "        return pd.DataFrame(columns=['title','genres','score'])\n",
    "\n",
    "    # --- CF part on train_movies ---\n",
    "    r_u     = pivot.loc[user_id].values               # (M',)\n",
    "    cf_train= sim_matrix.dot(r_u)                     # (M',)\n",
    "    cf_train= cf_train / abs_sim_sum                  # (M',)\n",
    "\n",
    "    # expand CF into full movie list\n",
    "    cf_full = np.zeros(len(all_movies))\n",
    "    # for each train_movie at position i, find its index j in all_movies\n",
    "    # and copy the CF score there\n",
    "    for i, m in enumerate(train_movies):\n",
    "        j = np.searchsorted(all_movies, m)\n",
    "        cf_full[j] = cf_train[i]\n",
    "\n",
    "    # --- CBF part on all_movies ---\n",
    "    prof    = user_profiles.get(user_id, np.zeros(movie_norm_full.shape[1]))\n",
    "    cbf_full= movie_norm_full.dot(prof)                # (M_full,)\n",
    "\n",
    "    # # --- blend & mask seen ---\n",
    "    # hyb     = a*cf_full + (1-a)*cbf_full\n",
    "    # seen    = set(train_ratings.query(\"userId==@user_id\").movieId)\n",
    "    # mask    = np.isin(all_movies, list(seen), invert=True)\n",
    "    # hyb    *= mask\n",
    "\n",
    "        # --- blend ---\n",
    "    hyb = a*cf_full + (1-a)*cbf_full\n",
    "\n",
    "    # 1) ban every warm‐movie (so Top-K is drawn only from the cold set)\n",
    "    hyb[pos_train_in_all] = -np.inf\n",
    "\n",
    "    # 2) still remove any the user actually rated in train\n",
    "    seen    = set(train_ratings.query(\"userId==@user_id\").movieId)\n",
    "    pos_seen = np.searchsorted(all_movies, list(seen))\n",
    "    hyb[pos_seen] = -np.inf\n",
    "\n",
    "    # --- top-K selection ---\n",
    "    idx     = np.argpartition(-hyb, K)[:K]\n",
    "    ordered = idx[np.argsort(-hyb[idx])]\n",
    "    picks   = all_movies[ordered]\n",
    "    scores  = hyb[ordered]\n",
    "\n",
    "    df = movies_small.set_index('movieId').loc[picks, ['title','genres']].copy()\n",
    "    df['score'] = scores\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e125379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Top-10 Hybrid Recs (userCF): 100%|██████████| 1000/1000 [00:43<00:00, 23.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated recommendations for 1000 users out of 1000 sampled.\n"
     ]
    }
   ],
   "source": [
    "# K      = 10\n",
    "# N      = 1000\n",
    "# valid_users = list(set(pivot.index) | set(user_profiles.keys()))\n",
    "# subset_user_ids = random.sample(valid_users, min(N, len(valid_users)))\n",
    "\n",
    "# preds = {}\n",
    "# for u in tqdm(subset_user_ids, desc=f\"Generating Top-{K} Hybrid Recs (userCF)\"):\n",
    "#     recs_df = recommend_hybrid_fast_uCF(u, K=K)\n",
    "#     if not recs_df.empty:\n",
    "#         preds[int(u)] = recs_df.index.tolist()\n",
    "\n",
    "# Path(\"predictions\").mkdir(exist_ok=True)\n",
    "# with open(\"predictions/hybrid_userCF_top10_subset.json\", \"w\") as f:\n",
    "#     json.dump(preds, f)\n",
    "\n",
    "# print(f\"Generated recommendations for {len(preds)} users out of {len(subset_user_ids)} sampled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975631c",
   "metadata": {},
   "source": [
    "# ColdStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d48c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 0) PICK SCENARIO: \"STANDARD\", \"USER\" (new-user cold), or \"ITEM\" (new-item cold)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "scenario = \"ITEM\"   # or \"USER\", or \"ITEM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17fd0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if scenario == \"STANDARD\":\n",
    "    ratings_small = pd.read_csv(\"subset_ratings.csv\", usecols=[\"userId\",\"movieId\",\"rating\"])\n",
    "    train_ratings, test_ratings = split_per_user(ratings_small)\n",
    "\n",
    "elif scenario == \"USER\":\n",
    "    train_ratings = pd.read_csv(\"evaluation/user_cold_train.csv\", usecols=[\"userId\",\"movieId\",\"rating\"])\n",
    "    test_ratings  = pd.read_csv(\"evaluation/user_cold_test.csv\",  usecols=[\"userId\",\"movieId\",\"rating\"])\n",
    "\n",
    "else:  # \"ITEM\"\n",
    "    train_ratings = pd.read_csv(\"evaluation/item_cold_train.csv\", usecols=[\"userId\",\"movieId\",\"rating\"])\n",
    "    test_ratings  = pd.read_csv(\"evaluation/item_cold_test.csv\",  usecols=[\"userId\",\"movieId\",\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423a8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# # 1) FILTER to movies for which we have tags\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# valid_movies   = set(movie_norm.index)\n",
    "# train_ratings  = train_ratings [train_ratings .movieId.isin(valid_movies)].reset_index(drop=True)\n",
    "# test_ratings   = test_ratings  [test_ratings  .movieId.isin(valid_movies)].reset_index(drop=True)\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# # 2) REBUILD user_profiles from train_ratings\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# min_r, max_r = train_ratings.rating.min(), train_ratings.rating.max()\n",
    "# user_profiles = {}\n",
    "# for u, grp in train_ratings.groupby(\"userId\"):\n",
    "#     feats   = movie_norm.loc[grp.movieId].values\n",
    "#     weights = ((grp.rating - min_r) / (max_r - min_r)).values[:, None]\n",
    "#     vec     = (weights * feats).sum(axis=0)\n",
    "#     if vec.sum() > 0:\n",
    "#         vec /= np.linalg.norm(vec)\n",
    "#     user_profiles[u] = vec\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# # 3) REBUILD CF structures (pivot, sim_users, abs_sim_u)\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# pivot      = train_ratings.pivot(index=\"userId\", columns=\"movieId\", values=\"rating\").fillna(0)\n",
    "# user_vecs  = pivot.values                           # U×M\n",
    "# user_ids   = pivot.index.values                     # length U\n",
    "# movie_ids  = pivot.columns.values.astype(int)       # length M\n",
    "\n",
    "# sim_users  = cosine_similarity(user_vecs)            # U×U\n",
    "# abs_sim_u  = np.sum(np.abs(sim_users), axis=1)      # length U\n",
    "\n",
    "# # align content‐based matrix to the pivot’s movie order\n",
    "# movie_norm_arr = movie_norm.loc[movie_ids].values   # M×T\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# # 4) GENERATE Top-K for every user in test_ratings\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# K = 10\n",
    "# preds_ucf = {}\n",
    "\n",
    "# for u in tqdm(test_ratings.userId.unique(), desc=f\"Hybrid-uCF Top-{K} ({scenario})\"):\n",
    "#     df_rec = recommend_hybrid_fast_uCF(u, K=K, a=0.7)\n",
    "#     preds_ucf[int(u)] = df_rec.index.tolist()  # even empty list if no recs\n",
    "\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# # 5) DUMP to JSON\n",
    "# # ─────────────────────────────────────────────────────────────────────────────\n",
    "# outfn = Path(\"coldstart_pred\") / f\"hybrid_userCF_{scenario.lower()}_top{K}.json\"\n",
    "# outfn.parent.mkdir(exist_ok=True)\n",
    "# with open(outfn, \"w\") as f:\n",
    "#     json.dump(preds_ucf, f, indent=2)\n",
    "\n",
    "# print(f\"✅  Saved {len(preds_ucf)} users → {outfn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c43989f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hybrid Top-10 (ITEM): 100%|██████████| 9787/9787 [05:17<00:00, 30.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved 9787 users → coldstart_pred\\hybrid_item_top10.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "# ITEM‐cold scenario\n",
    "# ───────────────────────────────────────────────────────────────────────\n",
    "scenario = \"ITEM\"\n",
    "if scenario == \"ITEM\":\n",
    "    # 4a) load your pre-split cold-item CSVs\n",
    "    train_ratings = pd.read_csv(\"evaluation/item_cold_train.csv\", usecols=[\"userId\",\"movieId\",\"rating\"])\n",
    "    test_ratings  = pd.read_csv(\"evaluation/item_cold_test.csv\",  usecols=[\"userId\",\"movieId\",\"rating\"])\n",
    "\n",
    "    # 4b) filter to only movies we have tags for\n",
    "    valid = set(movie_norm.index)\n",
    "    train_ratings = train_ratings[train_ratings.movieId.isin(valid)].reset_index(drop=True)\n",
    "    test_ratings  = test_ratings [test_ratings.movieId.isin(valid)].reset_index(drop=True)\n",
    "\n",
    "    # 4c) rebuild CF structures on train_ratings\n",
    "    pivot      = train_ratings.pivot(\n",
    "                      index=\"userId\", columns=\"movieId\", values=\"rating\"\n",
    "                  ).fillna(0)\n",
    "    # scale to [0,1]\n",
    "    scaled     = MinMaxScaler().fit_transform(pivot)\n",
    "    pivot.iloc[:,:] = scaled\n",
    "\n",
    "    # item–item similarity among the train set movies\n",
    "    train_movies = pivot.columns.values.astype(int)   # M' movies\n",
    "    item_vecs    = pivot.values.T                      # M'×U\n",
    "    sim_matrix   = cosine_similarity(item_vecs)        # M'×M'\n",
    "    abs_sim_sum  = np.sum(np.abs(sim_matrix), axis=1)  # length M'\n",
    "\n",
    "    # full list of genome‐tagged movies\n",
    "    all_movies      = np.array(sorted(movie_norm.index), dtype=int)  # M_full\n",
    "    movie_norm_full = movie_norm.loc[all_movies].values             # M_full×T\n",
    "\n",
    "    # rebuild user_profiles just in case\n",
    "    min_r, max_r = train_ratings.rating.min(), train_ratings.rating.max()\n",
    "    user_profiles = {}\n",
    "    for u, grp in train_ratings.groupby(\"userId\"):\n",
    "        feats   = movie_norm.loc[grp.movieId].values\n",
    "        wts     = ((grp.rating - min_r) / (max_r - min_r)).values[:,None]\n",
    "        prof    = (wts * feats).sum(0)\n",
    "        if prof.sum(): prof /= np.linalg.norm(prof)\n",
    "        user_profiles[u] = prof\n",
    "\n",
    "    # 4d) now generate Top-K with your item‐cold hybrid\n",
    "    preds_item = {}\n",
    "    for u in tqdm(test_ratings.userId.unique(), desc=\"Hybrid Top-10 (ITEM)\"):\n",
    "        df = recommend_hybrid_item(u, K=10, a=0.7)\n",
    "        preds_item[int(u)] = df.index.tolist()\n",
    "\n",
    "    # 4e) dump to JSON\n",
    "    outfn = Path(\"coldstart_pred\")/f\"hybrid_item_top10.json\"\n",
    "    outfn.parent.mkdir(exist_ok=True)\n",
    "    with open(outfn,\"w\") as fp:\n",
    "        json.dump(preds_item, fp, indent=2)\n",
    "    print(\"✅ saved\", len(preds_item), \"users →\", outfn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82262c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
